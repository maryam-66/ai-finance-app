# Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ÙØ§Ø±Ø³ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø± PDF (fpdf2 + arabic_reshaper + bidi)

import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from ta.trend import SMAIndicator, MACD
from ta.momentum import RSIIndicator
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk
import streamlit as st
import requests
from fpdf import FPDF
from io import BytesIO
import os
import arabic_reshaper
from bidi.algorithm import get_display

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ§Ú˜Ú¯Ø§Ù† VADER
try:
    nltk.data.find('sentiment/vader_lexicon.zip')
except LookupError:
    nltk.download('vader_lexicon')

# ØªÙ†Ø¸ÛŒÙ… ØµÙØ­Ù‡
st.set_page_config(page_title="ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø§Ø± Ù…Ø§Ù„ÛŒ", layout="centered")
st.title("ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª")

# ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§
symbols = st.multiselect("Ù†Ù…Ø§Ø¯Ù‡Ø§:", ["AAPL", "GOOGL", "MSFT", "BTC", "ETH", "GOLD", "SILVER"], default=["AAPL"])
start_date = st.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹", pd.to_datetime("2021-01-01"))
end_date = st.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†", pd.to_datetime("2024-12-31"))

# ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª
st.subheader("ğŸ§  ØªØ­Ù„ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± Ùˆ Ø§Ø­Ø³Ø§Ø³Ø§Øª")
newsapi_key = "1fbbb3b298474644b2187f4a534484d4"
run_analysis = st.button("ØªØ­Ù„ÛŒÙ„ Ø§Ø®Ø¨Ø§Ø± Ùˆ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´")

if run_analysis:
    all_data = []
    analyzer = SentimentIntensityAnalyzer()
    for symbol in symbols:
        url = f"https://newsapi.org/v2/everything?q={symbol}&sortBy=publishedAt&language=en&pageSize=5&apiKey={newsapi_key}"
        r = requests.get(url)
        if r.status_code == 200:
            articles = r.json().get("articles", [])
            for article in articles:
                text = f"{article.get('title', '')}. {article.get('description', '')}"
                score = analyzer.polarity_scores(text)
                all_data.append({
                    "symbol": symbol,
                    "date": article.get("publishedAt", "")[:10],
                    "title": article.get("title", ""),
                    "compound": score['compound'],
                    "pos": score['pos'],
                    "neg": score['neg'],
                    "neu": score['neu']
                })
        else:
            st.warning(f"âŒ Ø®Ø·Ø§ Ø¨Ø±Ø§ÛŒ {symbol}: {r.status_code}")

    if all_data:
        df = pd.DataFrame(all_data)
        st.success("âœ… ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
        st.dataframe(df)

        # Ø®Ù„Ø§ØµÙ‡ Ø¢Ù…Ø§Ø±ÛŒ Ú©Ù„ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª
        st.subheader("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ú©Ù„ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª")
        avg_scores = df[['pos', 'neg', 'neu', 'compound']].mean()
        st.write("Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø­Ø³Ø§Ø³Ø§Øª:")
        st.dataframe(avg_scores.to_frame(name='Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†'))

        # ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ú©Ù„ÛŒ
        st.subheader("ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ú©Ù„ÛŒ")
        fig_bar, ax_bar = plt.subplots()
        avg_scores[['pos', 'neg', 'neu']].plot(kind='bar', ax=ax_bar, color=['green', 'red', 'gray'])
        ax_bar.set_ylabel("Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù†Ù…Ø±Ù‡")
        ax_bar.set_title("Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…Ø«Ø¨ØªØŒ Ù…Ù†ÙÛŒØŒ Ø®Ù†Ø«ÛŒ")
        st.pyplot(fig_bar)

        # Ø®Ø±ÙˆØ¬ÛŒ Ø§Ú©Ø³Ù„
        excel_buf = BytesIO()
        df.to_excel(excel_buf, index=False)
        st.download_button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ Excel", data=excel_buf.getvalue(), file_name="sentiment.xlsx")

        # PDF Ø¨Ø§ Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ùˆ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø² ÙØ§Ø±Ø³ÛŒ
        from fpdf import FPDF

        class PDF(FPDF):
            pass

        pdf = PDF()
        pdf.add_page()
        pdf.add_font("DejaVu", "", fname="DejaVuSans.ttf", uni=True)
        pdf.add_font("DejaVu", "B", fname="DejaVuSans-Bold.ttf", uni=True)
        pdf.set_font("DejaVu", size=12)
        title = get_display(arabic_reshaper.reshape("ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø§Ø®Ø¨Ø§Ø± Ù…Ø§Ù„ÛŒ"))
        pdf.cell(200, 10, txt=title, ln=True, align="C")

        for symbol, group in df.groupby("symbol"):
            pdf.set_font("DejaVu", style="B", size=12)
            pdf.ln(10)
            sym_txt = get_display(arabic_reshaper.reshape(f"Ù†Ù…Ø§Ø¯: {symbol}"))
            pdf.cell(0, 10, txt=sym_txt, ln=True)
            pdf.set_font("DejaVu", size=11)
            for _, row in group.iterrows():
                fa_title = get_display(arabic_reshaper.reshape(row['title']))
                date = row['date']
                compound = row['compound']
                sentiment_txt = get_display(arabic_reshaper.reshape(f"Ø§Ø­Ø³Ø§Ø³ Ú©Ù„ÛŒ: {compound:.2f}"))
                pdf.multi_cell(0, 10, txt=f"{date}\n{fa_title}\n{sentiment_txt}\n")

            # Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª
            fig, ax = plt.subplots()
            sentiments = group[['pos', 'neg', 'neu']].mean()
            ax.pie(sentiments, labels=['Ù…Ø«Ø¨Øª', 'Ù…Ù†ÙÛŒ', 'Ø®Ù†Ø«ÛŒ'], autopct='%1.1f%%')
            ax.axis('equal')
            chart_buf = BytesIO()
            plt.savefig(chart_buf, format='png')
            plt.close(fig)
            chart_path = f"{symbol}_chart.png"
            with open(chart_path, "wb") as f:
                f.write(chart_buf.getvalue())
            pdf.image(chart_path, w=100)
            os.remove(chart_path)

        pdf.output("report.pdf")
        with open("report.pdf", "rb") as f:
            pdf_bytes = f.read()
        st.download_button("â¬‡ï¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ PDF", data=pdf_bytes, file_name="sentiment_report.pdf")
    else:
        st.error("Ù‡ÛŒÚ† Ø®Ø¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
